{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from collections import namedtuple\n",
    "import util as cm\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_skeleton_tracking_alg(skeletrack, color_image, depth_image, depth_intrinsic, baseline_done): \n",
    "    \n",
    "    depth_scaled = depth_image * 0.0010000000474974513\n",
    "    \n",
    "    # perform inference and update the tracking id\n",
    "    skeletons = skeletrack.track_skeletons(color_image)\n",
    "    \n",
    "    # render the skeletons on top of the acquired image and display it\n",
    "    color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "    depth_image_color = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.1), cv2.COLORMAP_JET)\n",
    "    \n",
    "    # render leg position on image \n",
    "    if len(skeletons) > 0: \n",
    "        try: \n",
    "            detect_legs_and_angle(depth_image_color, skeletons[0])\n",
    "        except: \n",
    "            None\n",
    "        try:    \n",
    "            if not baseline_done: \n",
    "                original_x = np.mean([skeletons[0].joints[5][0], skeletons[0].joints[2][0]])\n",
    "            computed_side_movement(depth_image_color, skeletons[0], original_x)\n",
    "        except Exception as e: \n",
    "            print('error in side to side movement')\n",
    "            print(e)\n",
    "            \n",
    "        try: \n",
    "            if not baseline_done: \n",
    "                x_ls, y_ls = int(skeletons[0].joints[5][0]), int(skeletons[0].joints[5][1])\n",
    "                x_rs, y_rs = int(skeletons[0].joints[2][0]), int(skeletons[0].joints[2][1])\n",
    "                x_mid, y_mid = int(skeletons[0].joints[1][0]), int(skeletons[0].joints[1][1])\n",
    "                z_ls, z_rs, z_mid = depth_scaled[y_ls, x_ls], depth_scaled[y_rs, x_rs], depth_scaled[y_mid, x_mid]\n",
    "                ref_z = np.mean([z_ls, z_rs, z_mid])\n",
    "            compute_rocking(depth_scaled, depth_image_color, skeletons[0], ref_z)\n",
    "        except Exception as e: \n",
    "            print('error in rocking')\n",
    "            print(e)\n",
    "            \n",
    "    # obtain region of interest for chest using skeleton points \n",
    "    curr_y_ls, curr_y_rs = int(skeletons[0].joints[5][1]), int(skeletons[0].joints[2][1])\n",
    "    curr_x_la, curr_x_ra = int(skeletons[0].joints[6][0]), int(skeletons[0].joints[3][0])\n",
    "    curr_x_lw, curr_y_lw = int(skeletons[0].joints[11][0]), int(skeletons[0].joints[11][1])\n",
    "    curr_x_rw, curr_y_rw = int(skeletons[0].joints[8][0]), int(skeletons[0].joints[8][1])\n",
    "    \n",
    "    chest_y0 = max(curr_y_ls, curr_y_rs)\n",
    "    bottom_y = min(curr_y_lw, curr_y_rw)\n",
    "    chest_y1 = (chest_y0 + bottom_y) // 2\n",
    "    \n",
    "    chest_roi = depth_scaled[chest_y0:bottom_y,curr_x_ra:curr_x_la]\n",
    "    depth_imgs.append(chest_roi)\n",
    "    chest_dist = np.mean(chest_roi)\n",
    "    distances.append(chest_dist)\n",
    "            \n",
    "    cm.render_result(skeletons, depth_image_color, joint_confidence)\n",
    "    render_ids_3d(depth_image_color, skeletons, depth.as_depth_frame(), depth_intrinsic, joint_confidence)\n",
    "    \n",
    "    cv2.imshow(window_name, depth_image_color)\n",
    "    \n",
    "    return\n",
    "\n",
    "def render_ids_3d(render_image, skeletons_2d, depth_map, depth_intrinsic, joint_confidence):\n",
    "    thickness = 1\n",
    "    text_color = (255, 255, 255)\n",
    "    rows, cols, channel = render_image.shape[:3]\n",
    "    distance_kernel_size = 5\n",
    "    # calculate 3D keypoints and display them\n",
    "    for skeleton_index in range(len(skeletons_2d)):\n",
    "        skeleton_2D = skeletons_2d[skeleton_index]\n",
    "        joints_2D = skeleton_2D.joints\n",
    "        did_once = False\n",
    "        for joint_index in range(len(joints_2D)):\n",
    "            if did_once == False:\n",
    "                cv2.putText(\n",
    "                    render_image,\n",
    "                    \"id: \" + str(skeleton_2D.id),\n",
    "                    (int(joints_2D[joint_index].x), int(joints_2D[joint_index].y - 30)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.55,\n",
    "                    text_color,\n",
    "                    thickness,\n",
    "                )\n",
    "                did_once = True\n",
    "            # check if the joint was detected and has valid coordinate\n",
    "            if skeleton_2D.confidences[joint_index] > joint_confidence:\n",
    "                distance_in_kernel = []\n",
    "                low_bound_x = max(\n",
    "                    0,\n",
    "                    int(\n",
    "                        joints_2D[joint_index].x - math.floor(distance_kernel_size / 2)\n",
    "                    ),\n",
    "                )\n",
    "                upper_bound_x = min(\n",
    "                    cols - 1,\n",
    "                    int(joints_2D[joint_index].x + math.ceil(distance_kernel_size / 2)),\n",
    "                )\n",
    "                low_bound_y = max(\n",
    "                    0,\n",
    "                    int(\n",
    "                        joints_2D[joint_index].y - math.floor(distance_kernel_size / 2)\n",
    "                    ),\n",
    "                )\n",
    "                upper_bound_y = min(\n",
    "                    rows - 1,\n",
    "                    int(joints_2D[joint_index].y + math.ceil(distance_kernel_size / 2)),\n",
    "                )\n",
    "                for x in range(low_bound_x, upper_bound_x):\n",
    "                    for y in range(low_bound_y, upper_bound_y):\n",
    "                        distance_in_kernel.append(depth_map.get_distance(x, y))\n",
    "                median_distance = np.percentile(np.array(distance_in_kernel), 50)\n",
    "                depth_pixel = [\n",
    "                    int(joints_2D[joint_index].x),\n",
    "                    int(joints_2D[joint_index].y),\n",
    "                ]\n",
    "                if median_distance >= 0.3:\n",
    "                    point_3d = rs.rs2_deproject_pixel_to_point(\n",
    "                        depth_intrinsic, depth_pixel, median_distance\n",
    "                    )\n",
    "                    point_3d = np.round([float(i) for i in point_3d], 3)\n",
    "                    point_str = [str(x) for x in point_3d]\n",
    "                    cv2.putText(\n",
    "                        render_image,\n",
    "                        str(point_3d),\n",
    "                        (int(joints_2D[joint_index].x), int(joints_2D[joint_index].y)),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX,\n",
    "                        0.4,\n",
    "                        text_color,\n",
    "                        thickness,\n",
    "                    )\n",
    "                    \n",
    "def compute_orientation(img, display=False):\n",
    "    \n",
    "    # apply threshold\n",
    "    thresh = threshold_otsu(img)\n",
    "    bw = closing(img > thresh, square(3))\n",
    "\n",
    "    label_img = label(bw)\n",
    "    props = regionprops(label_img)\n",
    "\n",
    "    # largest img\n",
    "    largest_index = np.argmax([p.area for p in props])\n",
    "    prop = props[largest_index]\n",
    "    \n",
    "    if display: \n",
    "\n",
    "        plt.figure()\n",
    "        plt.imshow(prop.image)\n",
    "\n",
    "        x0 = prop['Centroid'][1]\n",
    "        y0 = prop['Centroid'][0]\n",
    "        x2 = x0 - math.sin(prop['Orientation']) * 0.9 * prop['MinorAxisLength']\n",
    "        y2 = y0 - math.cos(prop['Orientation']) * 0.9 * prop['MinorAxisLength']\n",
    "\n",
    "        plt.plot((x0, x2), (y0, y2), '-r', linewidth=2.5)\n",
    "        plt.plot(x0, y0, '.g', markersize=15)\n",
    "\n",
    "        minr, minc, maxr, maxc = prop['BoundingBox']\n",
    "        bx = (minc, maxc, maxc, minc, minc)\n",
    "        by = (minr, minr, maxr, maxr, minr)\n",
    "        \n",
    "        plt.plot(bx, by, '-b', linewidth=2.5)\n",
    "        plt.show()\n",
    "        \n",
    "    return prop.orientation\n",
    "\n",
    "def detect_legs(img, skeleton): \n",
    "    \n",
    "    x_rk, y_rk = int(skeleton.joints[9][0]), int(skeleton.joints[9][1])\n",
    "    x_ra, y_ra = int(skeleton.joints[10][0]), int(skeleton.joints[10][1])\n",
    "    x_lk, y_lk = int(skeleton.joints[12][0]), int(skeleton.joints[12][1])\n",
    "    x_la, y_la = int(skeleton.joints[13][0]), int(skeleton.joints[13][1])\n",
    "    \n",
    "    # zero out each leg\n",
    "    img_left_leg = np.zeros(img.shape,np.uint8)\n",
    "    img_left_leg[y_lk:y_la, x_la-30:x_la+30] = img[y_lk:y_la, x_la-30:x_la+30]\n",
    "    img_right_leg = np.zeros(img.shape, np.uint8)\n",
    "    img_right_leg[y_rk:y_ra, y_ra-30:y_ra+30] = img[y_rk:y_ra, x_ra-30:x_ra+30]\n",
    "\n",
    "    # threshold each leg \n",
    "    gray_left = cv2.cvtColor(img_left_leg, cv2.COLOR_BGR2GRAY)\n",
    "    ret_left, thresh_left = cv2.threshold(gray_left, 0, 255, cv2.THRESH_OTSU)\n",
    "    gray_right = cv2.cvtColor(img_right_leg, cv2.COLOR_BGR2GRAY)\n",
    "    ret_right, thresh_right = cv2.threshold(gray_right, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "    # find contours for each leg \n",
    "    x_l, y_l, w_l, h_l = cv2.boundingRect(thresh_left)\n",
    "    x_r, y_r, w_r, h_r = cv2.boundingRect(thresh_right)\n",
    "\n",
    "    final_img = cv2.rectangle(img, (x_l, y_l), (x_l + w_l, y_l + h_l), (36,255,12), 2)\n",
    "    final_img = cv2.rectangle(final_img, (x_r, y_r), (x_r + w_r, y_r + h_r), (36,255,12), 2)\n",
    "\n",
    "    # display\n",
    "    cv2.putText(final_img, 'left leg', (x_l, y_l-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "    cv2.putText(final_img, 'right leg', (x_r, y_r-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)\n",
    "\n",
    "    cv2.imshow('image', final_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def detect_legs_and_angle(img, skeleton, display=False): \n",
    "    \n",
    "    x_rk, y_rk = int(skeleton.joints[9][0]), int(skeleton.joints[9][1])\n",
    "    x_ra, y_ra = int(skeleton.joints[10][0]), int(skeleton.joints[10][1])\n",
    "    x_lk, y_lk = int(skeleton.joints[12][0]), int(skeleton.joints[12][1])\n",
    "    x_la, y_la = int(skeleton.joints[13][0]), int(skeleton.joints[13][1])\n",
    "        \n",
    "    # zero out each leg\n",
    "    img_left_leg = np.zeros(img.shape,np.uint8)\n",
    "    img_left_leg[y_lk:y_la-15, x_la-70:x_la+70] = img[y_lk:y_la-15, x_la-70:x_la+70]\n",
    "    img_right_leg = np.zeros(img.shape, np.uint8)\n",
    "    img_right_leg[y_rk:y_ra-15, x_ra-70:x_ra+70] = img[y_rk:y_ra-15, x_ra-70:x_ra+70]\n",
    "\n",
    "    # threshold each leg \n",
    "    gray_left = cv2.cvtColor(img_left_leg, cv2.COLOR_BGR2GRAY)\n",
    "    ret_left, thresh_left = cv2.threshold(gray_left, 0, 255, cv2.THRESH_OTSU)\n",
    "    gray_right = cv2.cvtColor(img_right_leg, cv2.COLOR_BGR2GRAY)\n",
    "    ret_right, thresh_right = cv2.threshold(gray_right, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "    # obtain contour\n",
    "    cntrs_left = cv2.findContours(thresh_left, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cntrs_left = cntrs_left[0] if len(cntrs_left) == 2 else cntrs_left[1]\n",
    "    cntrs_left = max(cntrs_left, key=cv2.contourArea)\n",
    "    cntrs_right = cv2.findContours(thresh_right, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cntrs_right = cntrs_right[0] if len(cntrs_right) == 2 else cntrs_right[1]\n",
    "    cntrs_right = max(cntrs_right, key=cv2.contourArea)\n",
    "\n",
    "    # get bounding box for legs\n",
    "    x_l, y_l, w_l, h_l = cv2.boundingRect(cntrs_left)\n",
    "    x_r, y_r, w_r, h_r = cv2.boundingRect(cntrs_right)\n",
    "\n",
    "    # fit ellipsoid to find orientation \n",
    "    ellipse_left, ellipse_right = cv2.fitEllipse(cntrs_left), cv2.fitEllipse(cntrs_right)\n",
    "\n",
    "    _, angle_l = get_angle_orienation(img, ellipse_left)\n",
    "    _, angle_r = get_angle_orienation(img, ellipse_right)\n",
    "\n",
    "    # display \n",
    "    if angle_l >= 80 and angle_l <= 101: \n",
    "        color_l = (36,255,12)\n",
    "        status_l = True\n",
    "    else: \n",
    "        color_l = (255,12,36)\n",
    "        status_l = False\n",
    "\n",
    "\n",
    "    if angle_r >= 80 and angle_r <= 101:\n",
    "        color_r = (36,255,12)\n",
    "        status_r = True\n",
    "    else: \n",
    "        color_r = (255,12,36)\n",
    "        status_r = False\n",
    "\n",
    "    cv2.putText(img, str(round(angle_l, 1)), (x_l, y_l-20), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color_l, 2)\n",
    "    cv2.rectangle(img, (x_l, y_l), (x_l + w_l, y_l + h_l), color_l, 2)\n",
    "\n",
    "    cv2.putText(img, str(round(angle_r, 1)), (x_r, y_r-20), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color_r, 2)\n",
    "    cv2.rectangle(img, (x_r, y_r), (x_r + w_r, y_r + h_r), color_r, 2)\n",
    "\n",
    "    if status_r and status_l: \n",
    "        cv2.putText(img, 'Legs Good Position', (img.shape[1]//2+200, img.shape[0]-25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 3)\n",
    "    else: \n",
    "        cv2.putText(img, 'Straighten Legs', (img.shape[1]//2+200, img.shape[0]-25), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,12,36), 3)\n",
    "    \n",
    "    if display: \n",
    "        cv2.imshow('image', img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "def get_angle_orienation(img, ellipse, draw_line=False): \n",
    "    \n",
    "    result = None\n",
    "    (xc, yc), (d1, d2), angle = ellipse\n",
    "    \n",
    "    # draw orienation line\n",
    "    rmajor = max(d1, d2) / 2\n",
    "    if angle > 90:\n",
    "        angle = angle - 90\n",
    "    else:\n",
    "        angle = angle + 90\n",
    "\n",
    "    xtop = xc + math.cos(math.radians(angle))*rmajor\n",
    "    ytop = yc + math.sin(math.radians(angle))*rmajor\n",
    "    xbot = xc + math.cos(math.radians(angle+180))*rmajor\n",
    "    ybot = yc + math.sin(math.radians(angle+180))*rmajor\n",
    "    \n",
    "    if draw_line:\n",
    "        result = cv2.line(img, (int(xtop),int(ytop)), (int(xbot),int(ybot)), (0, 0, 255), 3)\n",
    "    \n",
    "    return result, angle\n",
    "\n",
    "def compute_rocking(depth_img, colorized, skeleton, prev_z): \n",
    "    \n",
    "    # extract key points \n",
    "    x_ls, y_ls = int(skeleton.joints[5][0]), int(skeleton.joints[5][1])\n",
    "    x_rs, y_rs = int(skeleton.joints[2][0]), int(skeleton.joints[2][1])\n",
    "    x_mid, y_mid = int(skeleton.joints[1][0]), int(skeleton.joints[1][1])\n",
    "    z_ls, z_rs, z_mid = depth_img[y_ls, x_ls], depth_img[y_rs, x_rs], depth_img[y_mid, x_mid]\n",
    "        \n",
    "    # compare to last z location \n",
    "    avg_position = np.mean([z_ls, z_rs, z_mid])\n",
    "    # display bounding box and status of rocking\n",
    "    if abs(prev_z - avg_position) > .05: \n",
    "        cv2.putText(colorized, 'Rocking Detected', (x_ls+5, y_rs-70), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,12,36), 2)\n",
    "        cv2.rectangle(colorized, (x_rs, y_rs-20), (x_ls + 20, y_ls + 20), (255,12,36), 2)\n",
    "        \n",
    "def computed_side_movement(img, skeleton, prev_x): \n",
    "    \n",
    "    # extract key points \n",
    "    x_ls, y_ls = int(skeleton.joints[5][0]), int(skeleton.joints[5][1])\n",
    "    x_rs, y_rs = int(skeleton.joints[2][0]), int(skeleton.joints[2][1])\n",
    "    \n",
    "    # compare to previous x value and display \n",
    "    avg_position = np.mean([x_ls, x_rs])\n",
    "    if abs(prev_x - avg_position) > 5: \n",
    "        cv2.putText(img, 'Side Movement Detected', (x_ls+5, y_rs-40), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,12,36), 2)\n",
    "        cv2.rectangle(img, (x_rs, y_rs-20), (x_ls + 20, y_ls + 20), (255,12,36), 2)\n",
    "        \n",
    "def convert_depth_frame_to_pointcloud(depth_image, camera_intrinsics ):\n",
    "    \"\"\"\n",
    "    Convert the depthmap to a 3D point cloud\n",
    "    Parameters:\n",
    "    -----------\n",
    "    depth_frame : rs.frame() The depth_frame containing the depth map\n",
    "    camera_intrinsics : The intrinsic values of the imager in whose coordinate system the depth_frame is computed\n",
    "    Return:\n",
    "    ----------\n",
    "    x : array\n",
    "        The x values of the pointcloud in meters\n",
    "    y : array\n",
    "        The y values of the pointcloud in meters\n",
    "    z : array\n",
    "        The z values of the pointcloud in meters\n",
    "    \"\"\"\n",
    "\n",
    "    [height, width] = depth_image.shape\n",
    "\n",
    "    nx = np.linspace(0, width-1, width)\n",
    "    ny = np.linspace(0, height-1, height)\n",
    "    u, v = np.meshgrid(nx, ny)\n",
    "    x = (u.flatten() - camera_intrinsics.ppx)/camera_intrinsics.fx\n",
    "    y = (v.flatten() - camera_intrinsics.ppy)/camera_intrinsics.fy\n",
    "\n",
    "    z = depth_image.flatten() / 1000;\n",
    "    x = np.multiply(x,z)\n",
    "    y = np.multiply(y,z)\n",
    "\n",
    "    x = x[np.nonzero(z)]\n",
    "    y = y[np.nonzero(z)]\n",
    "    z = z[np.nonzero(z)]\n",
    "\n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: Apache 2.0. See LICENSE file in root directory.\n",
    "# Copyright(c) 2015-2017 Intel Corporation. All Rights Reserved.\n",
    "\n",
    "\"\"\"\n",
    "OpenGL Pointcloud viewer with http://pyglet.org\n",
    "Usage:\n",
    "------\n",
    "Mouse:\n",
    "    Drag with left button to rotate around pivot (thick small axes),\n",
    "    with right button to translate and the wheel to zoom.\n",
    "Keyboard:\n",
    "    [p]     Pause\n",
    "    [r]     Reset View\n",
    "    [d]     Cycle through decimation values\n",
    "    [z]     Toggle point scaling\n",
    "    [x]     Toggle point distance attenuation\n",
    "    [c]     Toggle color source\n",
    "    [l]     Toggle lighting\n",
    "    [f]     Toggle depth post-processing\n",
    "    [s]     Save PNG (./out.png)\n",
    "    [e]     Export points to ply (./out.ply)\n",
    "    [q/ESC] Quit\n",
    "Notes:\n",
    "------\n",
    "Using deprecated OpenGL (FFP lighting, matrix stack...) however, draw calls \n",
    "are kept low with pyglet.graphics.* which uses glDrawArrays internally.\n",
    "Normals calculation is done with numpy on CPU which is rather slow, should really\n",
    "be done with shaders but was omitted for several reasons - brevity, for lowering\n",
    "dependencies (pyglet doesn't ship with shader support & recommends pyshaders)\n",
    "and for reference.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import ctypes\n",
    "import pyglet\n",
    "import pyglet.gl as gl\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "def get_clipped_pointcloud(pointcloud, boundary):\n",
    "\n",
    "    assert (pointcloud.shape[0]>=2)\n",
    "    \n",
    "    pointcloud = pointcloud[:,np.logical_and(pointcloud[0,:]<boundary[1], pointcloud[0,:]>boundary[0])]\n",
    "    pointcloud = pointcloud[:,np.logical_and(pointcloud[1,:]<boundary[3], pointcloud[1,:]>boundary[2])]\n",
    "    \n",
    "    return pointcloud\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/a/6802723\n",
    "def rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis by theta radians.\n",
    "    \"\"\"\n",
    "    axis = np.asarray(axis)\n",
    "    axis = axis / math.sqrt(np.dot(axis, axis))\n",
    "    a = math.cos(theta / 2.0)\n",
    "    b, c, d = -axis * math.sin(theta / 2.0)\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "\n",
    "class AppState:\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.pitch, self.yaw = math.radians(-10), math.radians(-15)\n",
    "        self.translation = np.array([0, 0, 1], np.float32)\n",
    "        self.distance = 2\n",
    "        self.mouse_btns = [False, False, False]\n",
    "        self.paused = False\n",
    "        self.decimate = 0\n",
    "        self.scale = True\n",
    "        self.attenuation = False\n",
    "        self.color = True\n",
    "        self.lighting = False\n",
    "        self.postprocessing = False\n",
    "        self.baseline_done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.pitch, self.yaw, self.distance = 0, 0, 2\n",
    "        self.translation[:] = 0, 0, 1\n",
    "\n",
    "    @property\n",
    "    def rotation(self):\n",
    "        Rx = rotation_matrix((1, 0, 0), math.radians(-self.pitch))\n",
    "        Ry = rotation_matrix((0, 1, 0), math.radians(-self.yaw))\n",
    "        return np.dot(Ry, Rx).astype(np.float32)\n",
    "\n",
    "state = AppState()\n",
    "\n",
    "# Configure streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_device('020122061309')\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "other_stream, other_format = rs.stream.color, rs.format.rgb8\n",
    "config.enable_stream(other_stream, 640, 480, other_format, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "profile = pipeline.get_active_profile()\n",
    "\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "\n",
    "# Processing blocks\n",
    "pc = rs.pointcloud()\n",
    "decimate = rs.decimation_filter()\n",
    "decimate.set_option(rs.option.filter_magnitude, 2 ** state.decimate)\n",
    "colorizer = rs.colorizer()\n",
    "filters = [rs.disparity_transform(),\n",
    "           rs.spatial_filter(),\n",
    "           rs.temporal_filter(),\n",
    "           rs.disparity_transform(False)]\n",
    "\n",
    "# pyglet\n",
    "window = pyglet.window.Window(\n",
    "    config=gl.Config(\n",
    "        double_buffer=True,\n",
    "        samples=8  # MSAA\n",
    "    ),\n",
    "    resizable=True, vsync=True)\n",
    "keys = pyglet.window.key.KeyStateHandler()\n",
    "window.push_handlers(keys)\n",
    "\n",
    "def convert_fmt(fmt):\n",
    "    \"\"\"rs.format to pyglet format string\"\"\"\n",
    "    return {\n",
    "        rs.format.rgb8: 'RGB',\n",
    "        rs.format.bgr8: 'BGR',\n",
    "        rs.format.rgba8: 'RGBA',\n",
    "        rs.format.bgra8: 'BGRA',\n",
    "        rs.format.y8: 'L',\n",
    "    }[fmt]\n",
    "\n",
    "# Create a VertexList to hold pointcloud data\n",
    "# Will pre-allocates memory according to the attributes below\n",
    "vertex_list = pyglet.graphics.vertex_list(\n",
    "    w * h, 'v3f/stream', 't2f/stream', 'n3f/stream')\n",
    "# Create and allocate memory for our color data\n",
    "other_profile = rs.video_stream_profile(profile.get_stream(rs.stream.color))\n",
    "image_data = pyglet.image.ImageData(w, h, convert_fmt(\n",
    "    other_profile.format()), (gl.GLubyte * (w * h * 3))())\n",
    "\n",
    "fps_display = pyglet.window.FPSDisplay(window)\n",
    "\n",
    "\n",
    "@window.event\n",
    "def on_mouse_drag(x, y, dx, dy, buttons, modifiers):\n",
    "    w, h = map(float, window.get_size())\n",
    "\n",
    "    if buttons & pyglet.window.mouse.LEFT:\n",
    "        state.yaw -= dx * 0.5\n",
    "        state.pitch -= dy * 0.5\n",
    "\n",
    "    if buttons & pyglet.window.mouse.RIGHT:\n",
    "        dp = np.array((dx / w, -dy / h, 0), np.float32)\n",
    "        state.translation += np.dot(state.rotation, dp)\n",
    "\n",
    "    if buttons & pyglet.window.mouse.MIDDLE:\n",
    "        dz = dy * 0.01\n",
    "        state.translation -= (0, 0, dz)\n",
    "        state.distance -= dz\n",
    "\n",
    "\n",
    "def handle_mouse_btns(x, y, button, modifiers):\n",
    "    state.mouse_btns[0] ^= (button & pyglet.window.mouse.LEFT)\n",
    "    state.mouse_btns[1] ^= (button & pyglet.window.mouse.RIGHT)\n",
    "    state.mouse_btns[2] ^= (button & pyglet.window.mouse.MIDDLE)\n",
    "\n",
    "\n",
    "window.on_mouse_press = window.on_mouse_release = handle_mouse_btns\n",
    "\n",
    "\n",
    "@window.event\n",
    "def on_mouse_scroll(x, y, scroll_x, scroll_y):\n",
    "    dz = scroll_y * 0.1\n",
    "    state.translation -= (0, 0, dz)\n",
    "    state.distance -= dz\n",
    "\n",
    "\n",
    "def on_key_press(symbol, modifiers):\n",
    "    if symbol == pyglet.window.key.R:\n",
    "        state.reset()\n",
    "\n",
    "    if symbol == pyglet.window.key.P:\n",
    "        state.paused ^= True\n",
    "\n",
    "    if symbol == pyglet.window.key.D:\n",
    "        state.decimate = (state.decimate + 1) % 3\n",
    "        decimate.set_option(rs.option.filter_magnitude, 2 ** state.decimate)\n",
    "\n",
    "    if symbol == pyglet.window.key.C:\n",
    "        state.color ^= True\n",
    "\n",
    "    if symbol == pyglet.window.key.Z:\n",
    "        state.scale ^= True\n",
    "\n",
    "    if symbol == pyglet.window.key.X:\n",
    "        state.attenuation ^= True\n",
    "\n",
    "    if symbol == pyglet.window.key.L:\n",
    "        state.lighting ^= True\n",
    "\n",
    "    if symbol == pyglet.window.key.F:\n",
    "        state.postprocessing ^= True\n",
    "\n",
    "    if symbol == pyglet.window.key.S:\n",
    "        pyglet.image.get_buffer_manager().get_color_buffer().save('out.png')\n",
    "\n",
    "    if symbol == pyglet.window.key.Q:\n",
    "        window.close()\n",
    "\n",
    "window.push_handlers(on_key_press)\n",
    "\n",
    "def axes(size=1, width=1):\n",
    "    \"\"\"draw 3d axes\"\"\"\n",
    "    gl.glLineWidth(width)\n",
    "    pyglet.graphics.draw(6, gl.GL_LINES,\n",
    "                         ('v3f', (0, 0, 0, size, 0, 0,\n",
    "                                  0, 0, 0, 0, size, 0,\n",
    "                                  0, 0, 0, 0, 0, size)),\n",
    "                         ('c3f', (1, 0, 0, 1, 0, 0,\n",
    "                                  0, 1, 0, 0, 1, 0,\n",
    "                                  0, 0, 1, 0, 0, 1,\n",
    "                                  ))\n",
    "                         )\n",
    "\n",
    "\n",
    "def frustum(intrinsics):\n",
    "    \"\"\"draw camera's frustum\"\"\"\n",
    "    w, h = intrinsics.width, intrinsics.height\n",
    "    batch = pyglet.graphics.Batch()\n",
    "\n",
    "    for d in range(1, 6, 2):\n",
    "        def get_point(x, y):\n",
    "            p = rs.rs2_deproject_pixel_to_point(intrinsics, [x, y], d)\n",
    "            batch.add(2, gl.GL_LINES, None, ('v3f', [0, 0, 0] + p))\n",
    "            return p\n",
    "\n",
    "        top_left = get_point(0, 0)\n",
    "        top_right = get_point(w, 0)\n",
    "        bottom_right = get_point(w, h)\n",
    "        bottom_left = get_point(0, h)\n",
    "\n",
    "        batch.add(2, gl.GL_LINES, None, ('v3f', top_left + top_right))\n",
    "        batch.add(2, gl.GL_LINES, None, ('v3f', top_right + bottom_right))\n",
    "        batch.add(2, gl.GL_LINES, None, ('v3f', bottom_right + bottom_left))\n",
    "        batch.add(2, gl.GL_LINES, None, ('v3f', bottom_left + top_left))\n",
    "\n",
    "    batch.draw()\n",
    "\n",
    "\n",
    "def grid(size=1, n=10, width=1):\n",
    "    \"\"\"draw a grid on xz plane\"\"\"\n",
    "    gl.glLineWidth(width)\n",
    "    s = size / float(n)\n",
    "    s2 = 0.5 * size\n",
    "    batch = pyglet.graphics.Batch()\n",
    "\n",
    "    for i in range(0, n + 1):\n",
    "        x = -s2 + i * s\n",
    "        batch.add(2, gl.GL_LINES, None, ('v3f', (x, 0, -s2, x, 0, s2)))\n",
    "    for i in range(0, n + 1):\n",
    "        z = -s2 + i * s\n",
    "        batch.add(2, gl.GL_LINES, None, ('v3f', (-s2, 0, z, s2, 0, z)))\n",
    "\n",
    "    batch.draw()\n",
    "\n",
    "\n",
    "@window.event\n",
    "def on_draw():\n",
    "    window.clear()\n",
    "\n",
    "    gl.glEnable(gl.GL_DEPTH_TEST)\n",
    "    gl.glEnable(gl.GL_LINE_SMOOTH)\n",
    "\n",
    "    width, height = window.get_size()\n",
    "    gl.glViewport(0, 0, width, height)\n",
    "\n",
    "    gl.glMatrixMode(gl.GL_PROJECTION)\n",
    "    gl.glLoadIdentity()\n",
    "    gl.gluPerspective(60, width / float(height), 0.01, 20)\n",
    "\n",
    "    gl.glMatrixMode(gl.GL_TEXTURE)\n",
    "    gl.glLoadIdentity()\n",
    "    # texcoords are [0..1] and relative to top-left pixel corner, add 0.5 to center\n",
    "    gl.glTranslatef(0.5 / image_data.width, 0.5 / image_data.height, 0)\n",
    "    image_texture = image_data.get_texture()\n",
    "    # texture size may be increased by pyglet to a power of 2\n",
    "    tw, th = image_texture.owner.width, image_texture.owner.height\n",
    "    gl.glScalef(image_data.width / float(tw),\n",
    "                image_data.height / float(th), 1)\n",
    "\n",
    "    gl.glMatrixMode(gl.GL_MODELVIEW)\n",
    "    gl.glLoadIdentity()\n",
    "\n",
    "    gl.gluLookAt(0, 0, 0, 0, 0, 1, 0, -1, 0)\n",
    "\n",
    "    gl.glTranslatef(0, 0, state.distance)\n",
    "    gl.glRotated(state.pitch, 1, 0, 0)\n",
    "    gl.glRotated(state.yaw, 0, 1, 0)\n",
    "\n",
    "    if any(state.mouse_btns):\n",
    "        axes(0.1, 4)\n",
    "\n",
    "    gl.glTranslatef(0, 0, -state.distance)\n",
    "    gl.glTranslatef(*state.translation)\n",
    "\n",
    "    gl.glColor3f(0.5, 0.5, 0.5)\n",
    "    gl.glPushMatrix()\n",
    "    gl.glTranslatef(0, 0.5, 0.5)\n",
    "    grid()\n",
    "    gl.glPopMatrix()\n",
    "\n",
    "    psz = max(window.get_size()) / float(max(w, h)) if state.scale else 1\n",
    "    gl.glPointSize(psz)\n",
    "    distance = (0, 0, 1) if state.attenuation else (1, 0, 0)\n",
    "    gl.glPointParameterfv(gl.GL_POINT_DISTANCE_ATTENUATION,\n",
    "                          (gl.GLfloat * 3)(*distance))\n",
    "\n",
    "    if state.lighting:\n",
    "        ldir = [0.5, 0.5, 0.5]  # world-space lighting\n",
    "        ldir = np.dot(state.rotation, (0, 0, 1))  # MeshLab style lighting\n",
    "        ldir = list(ldir) + [0]  # w=0, directional light\n",
    "        gl.glLightfv(gl.GL_LIGHT0, gl.GL_POSITION, (gl.GLfloat * 4)(*ldir))\n",
    "        gl.glLightfv(gl.GL_LIGHT0, gl.GL_DIFFUSE,\n",
    "                     (gl.GLfloat * 3)(1.0, 1.0, 1.0))\n",
    "        gl.glLightfv(gl.GL_LIGHT0, gl.GL_AMBIENT,\n",
    "                     (gl.GLfloat * 3)(0.75, 0.75, 0.75))\n",
    "        gl.glEnable(gl.GL_LIGHT0)\n",
    "        gl.glEnable(gl.GL_NORMALIZE)\n",
    "        gl.glEnable(gl.GL_LIGHTING)\n",
    "\n",
    "    gl.glColor3f(1, 1, 1)\n",
    "    texture = image_data.get_texture()\n",
    "    gl.glEnable(texture.target)\n",
    "    gl.glBindTexture(texture.target, texture.id)\n",
    "    gl.glTexParameteri(\n",
    "        gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MAG_FILTER, gl.GL_NEAREST)\n",
    "\n",
    "    # comment this to get round points with MSAA on\n",
    "    gl.glEnable(gl.GL_POINT_SPRITE)\n",
    "\n",
    "    if not state.scale and not state.attenuation:\n",
    "        gl.glDisable(gl.GL_MULTISAMPLE)  # for true 1px points with MSAA on\n",
    "    vertex_list.draw(gl.GL_POINTS)\n",
    "    gl.glDisable(texture.target)\n",
    "    if not state.scale and not state.attenuation:\n",
    "        gl.glEnable(gl.GL_MULTISAMPLE)\n",
    "\n",
    "    gl.glDisable(gl.GL_LIGHTING)\n",
    "\n",
    "    gl.glColor3f(0.25, 0.25, 0.25)\n",
    "    frustum(depth_intrinsics)\n",
    "    axes()\n",
    "\n",
    "    gl.glMatrixMode(gl.GL_PROJECTION)\n",
    "    gl.glLoadIdentity()\n",
    "    gl.glOrtho(0, width, 0, height, -1, 1)\n",
    "    gl.glMatrixMode(gl.GL_MODELVIEW)\n",
    "    gl.glLoadIdentity()\n",
    "    gl.glMatrixMode(gl.GL_TEXTURE)\n",
    "    gl.glLoadIdentity()\n",
    "    gl.glDisable(gl.GL_DEPTH_TEST)\n",
    "\n",
    "    fps_display.draw()\n",
    "\n",
    "def run(dt):\n",
    "    global w, h\n",
    "    window.set_caption(\"RealSense (%dx%d) %dFPS (%.2fms) %s\" %\n",
    "                       (w, h, 0 if dt == 0 else 1.0 / dt, dt * 1000,\n",
    "                        \"PAUSED\" if state.paused else \"\"))\n",
    "    if state.paused:\n",
    "        return\n",
    "    \n",
    "    success, frames = pipeline.try_wait_for_frames(timeout_ms=0)\n",
    "    \n",
    "    if not success:\n",
    "        return\n",
    "\n",
    "    depth_frame = frames.get_depth_frame().as_video_frame()\n",
    "    other_frame = frames.first(other_stream).as_video_frame()\n",
    "\n",
    "    depth_frame = decimate.process(depth_frame)\n",
    "\n",
    "    if state.postprocessing:\n",
    "        for f in filters:\n",
    "            depth_frame = f.process(depth_frame)\n",
    "\n",
    "    # Grab new intrinsics (may be changed by decimation)\n",
    "    depth_intrinsics = rs.video_stream_profile(\n",
    "        depth_frame.profile).get_intrinsics()\n",
    "    w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "\n",
    "    color_image = np.asanyarray(other_frame.get_data())\n",
    "\n",
    "    colorized_depth = colorizer.colorize(depth_frame)\n",
    "    depth_colormap = np.asanyarray(colorized_depth.get_data())\n",
    "\n",
    "    if state.color:\n",
    "        mapped_frame, color_source = other_frame, color_image\n",
    "    else:\n",
    "        mapped_frame, color_source = colorized_depth, depth_colormap\n",
    "\n",
    "    points = pc.calculate(depth_frame)\n",
    "    pc.map_to(mapped_frame)\n",
    "\n",
    "    # handle color source or size change\n",
    "    fmt = convert_fmt(mapped_frame.profile.format())\n",
    "    global image_data\n",
    "    if (image_data.format, image_data.pitch) != (fmt, color_source.strides[0]):\n",
    "        empty = (gl.GLubyte * (w * h * 3))()\n",
    "        image_data = pyglet.image.ImageData(w, h, fmt, empty)\n",
    "    # copy image data to pyglet\n",
    "    image_data.set_data(fmt, color_source.strides[0], color_source.ctypes.data)\n",
    "    \n",
    "    texcoords = np.asarray(points.get_texture_coordinates(2))\n",
    "    verts = np.asarray(points.get_vertices(2))\n",
    "        \n",
    "    verts[np.where(verts[:,2]>2.4)] = [np.nan, np.nan, np.nan]\n",
    "#     verts[np.where(verts[:,2]<=2.2)] = [np.nan, np.nan, np.nan]\n",
    "#     verts = verts.reshape(h, w, 3)\n",
    "#     texcoords = texcoords.reshape(h, w , 2)\n",
    "    \n",
    "#     verts = verts[220:330, 210:440, :]\n",
    "#     texcoords = texcoords[220:330, 210:440]\n",
    "\n",
    "    if len(vertex_list.vertices) != verts.size:\n",
    "        vertex_list.resize(verts.size // 3)\n",
    "        \n",
    "        # need to reassign after resizing\n",
    "        vertex_list.vertices = verts.ravel()\n",
    "        vertex_list.tex_coords = texcoords.ravel()\n",
    "\n",
    "    # copy our data to pre-allocated buffers, this is faster than assigning...\n",
    "    # pyglet will take care of uploading to GPU\n",
    "    def copy(dst, src):\n",
    "        \"\"\"copy numpy array to pyglet array\"\"\"\n",
    "        # timeit was mostly inconclusive, favoring slice assignment for safety\n",
    "        np.array(dst, copy=False)[:] = src.ravel()\n",
    "        # ctypes.memmove(dst, src.ctypes.data, src.nbytes)\n",
    "\n",
    "    copy(vertex_list.vertices, verts)\n",
    "    copy(vertex_list.tex_coords, texcoords)\n",
    "\n",
    "    if state.lighting:\n",
    "        # compute normals\n",
    "        dy, dx = np.gradient(verts, axis=(0, 1))\n",
    "        n = np.cross(dx, dy)\n",
    "\n",
    "        copy(vertex_list.normals, n)\n",
    "\n",
    "    if keys[pyglet.window.key.E]:\n",
    "        points.export_to_ply('./out.ply', mapped_frame)\n",
    "\n",
    "pyglet.clock.schedule(run)\n",
    "try:\n",
    "    pyglet.app.run()\n",
    "finally:\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fheng_env)",
   "language": "python",
   "name": "fheng_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
